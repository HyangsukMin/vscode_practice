{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittensorconda64d372fd24d34c848179e7785e53eb20",
   "display_name": "Python 3.7.7 64-bit ('tensor': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter13 :Loading and Preprocessing Data with TensorFlow"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Code : [github.com/ageron/handson-ml2](https://github.com/ageron/handson-ml2/blob/master/13_loading_and_preprocessing_data.ipynb)\n",
    "\n",
    "Books : [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    !pip install -q -U tfx==0.21.2\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"data\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "source": [
    "## Split the California dataaset to multiple CSV files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1,1), random_state = 42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_"
   ]
  },
  {
   "source": [
    "\n",
    "For a very large dataset that does not fit in memory, you will typically want to split it into many files first, then have TensorFlow read these files in parallel. To demonstrate this, let's start by splitting the housing dataset and save it to 20 CSV files:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header = None, n_parts = 10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding='utf-8') as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths\n",
    "\n",
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "headers_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(headers_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data,\"train\",header,n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data,\"valid\",header,n_parts=20)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data,\"test\",header,n_parts=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n\n   Longitude  MedianHouseValue  \n0    -122.43             1.442  \n1    -117.39             1.687  \n2    -122.98             1.621  \n3    -117.70             2.621  \n4    -116.93             0.956  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>MedianHouseValue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.5214</td>\n      <td>15.0</td>\n      <td>3.049945</td>\n      <td>1.106548</td>\n      <td>1447.0</td>\n      <td>1.605993</td>\n      <td>37.63</td>\n      <td>-122.43</td>\n      <td>1.442</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.3275</td>\n      <td>5.0</td>\n      <td>6.490060</td>\n      <td>0.991054</td>\n      <td>3464.0</td>\n      <td>3.443340</td>\n      <td>33.69</td>\n      <td>-117.39</td>\n      <td>1.687</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.1000</td>\n      <td>29.0</td>\n      <td>7.542373</td>\n      <td>1.591525</td>\n      <td>1328.0</td>\n      <td>2.250847</td>\n      <td>38.44</td>\n      <td>-122.98</td>\n      <td>1.621</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.1736</td>\n      <td>12.0</td>\n      <td>6.289003</td>\n      <td>0.997442</td>\n      <td>1054.0</td>\n      <td>2.695652</td>\n      <td>33.55</td>\n      <td>-117.70</td>\n      <td>2.621</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0549</td>\n      <td>13.0</td>\n      <td>5.312457</td>\n      <td>1.085092</td>\n      <td>3297.0</td>\n      <td>2.244384</td>\n      <td>33.93</td>\n      <td>-116.93</td>\n      <td>0.956</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
    }
   ],
   "source": [
    "with open(train_filepaths[0]) as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline(),end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['datasets/housing/my_train_00.csv',\n 'datasets/housing/my_train_01.csv',\n 'datasets/housing/my_train_02.csv',\n 'datasets/housing/my_train_03.csv',\n 'datasets/housing/my_train_04.csv',\n 'datasets/housing/my_train_05.csv',\n 'datasets/housing/my_train_06.csv',\n 'datasets/housing/my_train_07.csv',\n 'datasets/housing/my_train_08.csv',\n 'datasets/housing/my_train_09.csv',\n 'datasets/housing/my_train_10.csv',\n 'datasets/housing/my_train_11.csv',\n 'datasets/housing/my_train_12.csv',\n 'datasets/housing/my_train_13.csv',\n 'datasets/housing/my_train_14.csv',\n 'datasets/housing/my_train_15.csv',\n 'datasets/housing/my_train_16.csv',\n 'datasets/housing/my_train_17.csv',\n 'datasets/housing/my_train_18.csv',\n 'datasets/housing/my_train_19.csv']"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page418\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n"
    }
   ],
   "source": [
    "for filepath in filepath_dataset:\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "b'4.5909,16.0,5.475877192982456,1.0964912280701755,1357.0,2.9758771929824563,33.63,-117.71,2.418'\nb'2.4792,24.0,3.4547038327526134,1.1341463414634145,2251.0,3.921602787456446,34.18,-118.38,2.0'\nb'4.2708,45.0,5.121387283236994,0.953757225433526,492.0,2.8439306358381504,37.48,-122.19,2.67'\nb'2.1856,41.0,3.7189873417721517,1.0658227848101265,803.0,2.0329113924050635,32.76,-117.12,1.205'\nb'4.1812,52.0,5.701388888888889,0.9965277777777778,692.0,2.4027777777777777,33.73,-118.31,3.215'\n"
    }
   ],
   "source": [
    "# interleave() : create a dataset that will pull five file paths from the `filepath_dataset`. and for each one it will call the function you gave it to create a new dataset\n",
    "# interleave() does not use parallelism -> num_parallel_calls -> 자동선택 tf.data.experimental.AUTOTUNE\n",
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers\n",
    ")\n",
    "\n",
    "for line in dataset.take(5):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n <tf.Tensor: shape=(), dtype=float32, numpy=2.0>,\n <tf.Tensor: shape=(), dtype=float64, numpy=3.0>,\n <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n <tf.Tensor: shape=(), dtype=float32, numpy=5.0>]"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "record_defaults = [0, np.nan, tf.constant(np.nan, dtype=tf.float64), \"Hello\", tf.constant([])]\n",
    "parsed_fields = tf.io.decode_csv('1,2,3,4,5', record_defaults)\n",
    "parsed_fields"
   ]
  },
  {
   "source": [
    "Notice that all missing fields are replaced with their default value, when provided:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<tf.Tensor: shape=(), dtype=int32, numpy=0>,\n <tf.Tensor: shape=(), dtype=float32, numpy=nan>,\n <tf.Tensor: shape=(), dtype=float64, numpy=nan>,\n <tf.Tensor: shape=(), dtype=string, numpy=b'Hello'>,\n <tf.Tensor: shape=(), dtype=float32, numpy=5.0>]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "parsed_filels = tf.io.decode_csv(',,,,5', record_defaults)\n",
    "parsed_filels"
   ]
  },
  {
   "source": [
    "\n",
    "The 5th field is compulsory (since we provided tf.constant([]) as the \"default value\"), so we get an exception if we do not provide it:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Field 4 is required but missing in record 0! [Op:DecodeCSV]\n"
    }
   ],
   "source": [
    "try :\n",
    "    parsed_fields = tf.io.decode_csv(',,,,',record_defaults)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "source": [
    "The number of fields should match exactly the number of fields in the record_defaults:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Expect 5 fields but have 7 in record 0 [Op:DecodeCSV]\n"
    }
   ],
   "source": [
    "try :\n",
    "    parsed_fields = tf.io.decode_csv('1,2,3,4,5,6,7', record_defaults)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "source": [
    "## Preprocessing the Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 8\n",
    "\n",
    "@tf.function\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)] \n",
    "    fields = tf.io.decode_csv(line,record_defaults=defs) # returns a list of scalar tensors\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n array([ 0.16579157,  1.216324  , -0.05204565, -0.39215982, -0.5277444 ,\n        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
   ]
  },
  {
   "source": [
    "## Putting Everything Together"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers = 5,\n",
    "                        n_read_threads = None, shuffle_buffer_size = 10000,\n",
    "                        n_parse_threads = 1, batch_size = 32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length = n_readers, num_parallel_calls = n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls = n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1) # we are creating a dataset that will od its best to always be one batch ahead"
   ]
  },
  {
   "source": [
    "<div>\n",
    "<img src=\"./images/ch13-loading-preprocessing-data-from-multiple-csv.png\" width=\"500\"/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X = tf.Tensor(\n[[ 0.5804519  -0.20762321  0.05616303 -0.15191229  0.01343246  0.00604472\n   1.2525111  -1.3671792 ]\n [ 5.818099    1.8491895   1.1784915   0.28173092 -1.2496178  -0.3571987\n   0.7231292  -1.0023477 ]\n [-0.9253566   0.5834586  -0.7807257  -0.28213993 -0.36530012  0.27389365\n  -0.76194876  0.72684526]], shape=(3, 8), dtype=float32)\ny = tf.Tensor(\n[[1.752]\n [1.313]\n [1.535]], shape=(3, 1), dtype=float32)\n\nX = tf.Tensor(\n[[-0.8324941   0.6625668  -0.20741376 -0.18699841 -0.14536144  0.09635526\n   0.9807942  -0.67250353]\n [-0.62183803  0.5834586  -0.19862501 -0.3500319  -1.1437552  -0.3363751\n   1.107282   -0.8674123 ]\n [ 0.8683102   0.02970133  0.3427381  -0.29872298  0.7124906   0.28026953\n  -0.72915536  0.86178064]], shape=(3, 8), dtype=float32)\ny = tf.Tensor(\n[[0.919]\n [1.028]\n [2.182]], shape=(3, 1), dtype=float32)\n\n"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "train_set = csv_reader_dataset(train_filepaths, batch_size= 3)\n",
    "for X_batch, y_batch in train_set.take(2):\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)\n",
    "    print()"
   ]
  },
  {
   "source": [
    "## Using the Dataset with tf.keras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = csv_reader_dataset(train_filepaths, repeat = None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "362/362 [==============================] - 3s 8ms/step - loss: 1.6214 - val_loss: 1.3046\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fe4a85edb50>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "batch_size = 32\n",
    "model.fit(train_set, steps_per_epoch=len(X_train) // batch_size, epochs=1,\n",
    "          validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "161/161 [==============================] - 1s 6ms/step - loss: 0.7987\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7986820936203003"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "model.evaluate(test_set, steps = len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1.1917185],\n       [2.3149984],\n       [2.7424657],\n       ...,\n       [2.2430615],\n       [4.291179 ],\n       [1.4645061]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "new_set = test_set.map(lambda X, y:X)\n",
    "model.predict(new_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Global step 362/362"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "n_epochs = 1\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "total_steps = n_epochs * n_steps_per_epoch\n",
    "global_step = 0\n",
    "for X_batch, y_batch in train_set.take(total_steps):\n",
    "    global_step += 1\n",
    "    print(\"\\rGlobal step {}/{}\".format(global_step, total_steps), end=\"\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X_batch)\n",
    "        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "        loss = tf.add_n([main_loss] + model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "source": [
    "## 밑에 방식 익숙해지기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Global step 100 / 362\nGlobal step 200 / 362\nGlobal step 300 / 362\n"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size = 32, n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat = n_epochs, n_readers = n_readers,\n",
    "    n_read_threads = n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "    n_parse_threads=n_parse_threads, batch_size = batch_size)\n",
    "    n_steps_per_epoch = len(X_train) // batch_size\n",
    "    total_steps = n_epochs * n_steps_per_epoch\n",
    "    global_step = 0\n",
    "    for X_batch, y_batch in train_set:\n",
    "        global_step += 1\n",
    "        if tf.equal(global_step % 100, 0):\n",
    "            tf.print(\"\\rGlobal step\", global_step, \"/\", total_steps)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss]+model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 1)"
   ]
  },
  {
   "source": [
    "Here is a short description of each method in the Dataset class:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "● apply()              Applies a transformation function to this dataset.\n● as_numpy_iterator()  Returns an iterator which converts all elements of the dataset to numpy.\n● batch()              Combines consecutive elements of this dataset into batches.\n● cache()              Caches the elements in this dataset.\n● concatenate()        Creates a `Dataset` by concatenating the given dataset with this dataset.\n● element_spec()       The type specification of an element of this dataset.\n● enumerate()          Enumerates the elements of this dataset.\n● filter()             Filters this dataset according to `predicate`.\n● flat_map()           Maps `map_func` across this dataset and flattens the result.\n● from_generator()     Creates a `Dataset` whose elements are generated by `generator`.\n● from_tensor_slices() Creates a `Dataset` whose elements are slices of the given tensors.\n● from_tensors()       Creates a `Dataset` with a single element, comprising the given tensors.\n● interleave()         Maps `map_func` across this dataset, and interleaves the results.\n● list_files()         A dataset of all files matching one or more glob patterns.\n● map()                Maps `map_func` across the elements of this dataset.\n● options()            Returns the options for this dataset and its inputs.\n● padded_batch()       Combines consecutive elements of this dataset into padded batches.\n● prefetch()           Creates a `Dataset` that prefetches elements from this dataset.\n● range()              Creates a `Dataset` of a step-separated range of values.\n● reduce()             Reduces the input dataset to a single element.\n● repeat()             Repeats this dataset so each original value is seen `count` times.\n● shard()              Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n● shuffle()            Randomly shuffles the elements of this dataset.\n● skip()               Creates a `Dataset` that skips `count` elements from this dataset.\n● take()               Creates a `Dataset` with at most `count` elements from this dataset.\n● unbatch()            Splits elements of a dataset into multiple elements.\n● window()             Combines (nests of) input elements into a dataset of (nests of) windows.\n● with_options()       Returns a new `tf.data.Dataset` with the given options set.\n● zip()                Creates a `Dataset` by zipping together the given datasets.\n"
    }
   ],
   "source": [
    "for m in dir(tf.data.Dataset):\n",
    "    if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
    "        func = getattr(tf.data.Dataset, m)\n",
    "        if hasattr(func, \"__doc__\"):\n",
    "            print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
   ]
  },
  {
   "source": [
    "## The TFRecord Format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "simple binary format that just contains a sequence of binary records of varysing sizes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(b'This is the first record', shape=(), dtype=string)\ntf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
    }
   ],
   "source": [
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(b'File 0 record 0', shape=(), dtype=string)\ntf.Tensor(b'File 1 record 0', shape=(), dtype=string)\ntf.Tensor(b'File 2 record 0', shape=(), dtype=string)\ntf.Tensor(b'File 0 record 1', shape=(), dtype=string)\ntf.Tensor(b'File 1 record 1', shape=(), dtype=string)\ntf.Tensor(b'File 2 record 1', shape=(), dtype=string)\ntf.Tensor(b'File 0 record 2', shape=(), dtype=string)\ntf.Tensor(b'File 1 record 2', shape=(), dtype=string)\ntf.Tensor(b'File 2 record 2', shape=(), dtype=string)\ntf.Tensor(b'File 3 record 0', shape=(), dtype=string)\ntf.Tensor(b'File 4 record 0', shape=(), dtype=string)\ntf.Tensor(b'File 3 record 1', shape=(), dtype=string)\ntf.Tensor(b'File 4 record 1', shape=(), dtype=string)\ntf.Tensor(b'File 3 record 2', shape=(), dtype=string)\ntf.Tensor(b'File 4 record 2', shape=(), dtype=string)\n"
    }
   ],
   "source": [
    "filepaths = [\"My_test_{}.tfrecord\".format(i) for i in range(5)]\n",
    "for i, filepath in enumerate(filepaths):\n",
    "    with tf.io.TFRecordWriter(filepath) as f:\n",
    "        for j in range(3):\n",
    "            f.write(\"File {} record {}\".format(i, j).encode('utf-8'))\n",
    "dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=3)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\",options) as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(b'File 0 record 0', shape=(), dtype=string)\ntf.Tensor(b'File 1 record 0', shape=(), dtype=string)\ntf.Tensor(b'File 2 record 0', shape=(), dtype=string)\ntf.Tensor(b'File 0 record 1', shape=(), dtype=string)\ntf.Tensor(b'File 1 record 1', shape=(), dtype=string)\ntf.Tensor(b'File 2 record 1', shape=(), dtype=string)\ntf.Tensor(b'File 0 record 2', shape=(), dtype=string)\ntf.Tensor(b'File 1 record 2', shape=(), dtype=string)\ntf.Tensor(b'File 2 record 2', shape=(), dtype=string)\ntf.Tensor(b'File 3 record 0', shape=(), dtype=string)\ntf.Tensor(b'File 4 record 0', shape=(), dtype=string)\ntf.Tensor(b'File 3 record 1', shape=(), dtype=string)\ntf.Tensor(b'File 4 record 1', shape=(), dtype=string)\ntf.Tensor(b'File 3 record 2', shape=(), dtype=string)\ntf.Tensor(b'File 4 record 2', shape=(), dtype=string)\n"
    }
   ],
   "source": [
    "cdataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],\n",
    "                                    compression_type=\"GZIP\")\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "source": [
    "## A Brief Introduction to Protocol Buffers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Writing person.proto\n"
    }
   ],
   "source": [
    "\n",
    "%%writefile person.proto\n",
    "syntax = \"proto3\";\n",
    "message Person {\n",
    "  string name = 1;\n",
    "  int32 id = 2;\n",
    "  repeated string email = 3;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "!protoc person.proto --python_out=. --descriptor_set_out=person.desc --include_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "person.desc  person_pb2.py  person.proto\n"
    }
   ],
   "source": [
    "!ls person*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "name: \"AI\"\nid: 123\nemail: \"a@b.com\"\n\n"
    }
   ],
   "source": [
    "from person_pb2 import Person\n",
    "\n",
    "person = Person(name=\"AI\", id=123, email=[\"a@b.com\"])\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'\\n\\x02AI\\x10{\\x1a\\x07a@b.com'"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "s = person.SerializeToString()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "15"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "person2 = Person()\n",
    "person2.ParseFromString(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "person == person2"
   ]
  },
  {
   "source": [
    "## TensorFlow Protobufs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.train import ByteList, FloatList, Int64List # -> Error\n",
    "# from tensorflow.train import Feature, Features, Example # -> Error\n",
    "BytesList = tf.train.BytesList\n",
    "FloatList = tf.train.FloatList\n",
    "Int64List = tf.train.Int64List\n",
    "Feature = tf.train.Feature\n",
    "Features = tf.train.Features\n",
    "Example = tf.train.Example\n",
    "\n",
    "person_example = Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
    "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", b\"c@d.com\"]))\n",
    "        }))\n",
    "        \n",
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"emails\": tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
    "    parsed_example = tf.io.parse_single_example(serialized_example,\n",
    "                                                feature_description)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'emails': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7fe4a861a950>,\n 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>,\n 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "parsed_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "parsed_example[\"emails\"].values"
   ]
  },
  {
   "source": [
    "## Handling Lists of Lists Using the SequenceExample Protobuf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.train import FeatureList, FeatureLists, SequenceExample\n",
    "FeatureList = tf.train.FeatureList\n",
    "FeatureLists = tf.train.FeatureLists\n",
    "SequenceExample = tf.train.SequenceExample\n",
    "BytesList = tf.train.BytesList\n",
    "\n",
    "context = Features(feature={\n",
    "    \"author_id\" : Feature(int64_list = Int64List(value=[123])),\n",
    "    \"title\" : Feature(bytes_list = BytesList(value=[b\"A\", b\"desert\",b\"place\",b\".\"])),\n",
    "    \"pub_date\" : Feature(int64_list = Int64List(value=[1623, 12, 25]))\n",
    "})\n",
    "\n",
    "content = [[\"When\", \"shall\", \"we\", \"three\", \"meet\", \"again\", \"?\"],\n",
    "           [\"In\", \"thunder\", \",\", \"lightning\", \",\", \"or\", \"in\", \"rain\", \"?\"]]\n",
    "comments = [[\"When\", \"the\", \"hurlyburly\", \"'s\", \"done\", \".\"],\n",
    "            [\"When\", \"the\", \"battle\", \"'s\", \"lost\", \"and\", \"won\", \".\"]]\n",
    "def words_to_feature(words):\n",
    "    return Feature(bytes_list = BytesList(value = [word.encode('utf-8')\n",
    "                                                    for word in words]))\n",
    "\n",
    "content_features = [words_to_feature(sentence) for sentence in content]\n",
    "comments_features = [words_to_feature(comment) for comment in comments]\n",
    "\n",
    "sequence_example = SequenceExample(\n",
    "    context = context,\n",
    "    feature_lists = FeatureLists(feature_list={\n",
    "        \"content\" : FeatureList(feature = content_features),\n",
    "        \"comments\" : FeatureList(feature = comments_features)\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "context {\n  feature {\n    key: \"author_id\"\n    value {\n      int64_list {\n        value: 123\n      }\n    }\n  }\n  feature {\n    key: \"pub_date\"\n    value {\n      int64_list {\n        value: 1623\n        value: 12\n        value: 25\n      }\n    }\n  }\n  feature {\n    key: \"title\"\n    value {\n      bytes_list {\n        value: \"A\"\n        value: \"desert\"\n        value: \"place\"\n        value: \".\"\n      }\n    }\n  }\n}\nfeature_lists {\n  feature_list {\n    key: \"comments\"\n    value {\n      feature {\n        bytes_list {\n          value: \"When\"\n          value: \"the\"\n          value: \"hurlyburly\"\n          value: \"\\'s\"\n          value: \"done\"\n          value: \".\"\n        }\n      }\n      feature {\n        bytes_list {\n          value: \"When\"\n          value: \"the\"\n          value: \"battle\"\n          value: \"\\'s\"\n          value: \"lost\"\n          value: \"and\"\n          value: \"won\"\n          value: \".\"\n        }\n      }\n    }\n  }\n  feature_list {\n    key: \"content\"\n    value {\n      feature {\n        bytes_list {\n          value: \"When\"\n          value: \"shall\"\n          value: \"we\"\n          value: \"three\"\n          value: \"meet\"\n          value: \"again\"\n          value: \"?\"\n        }\n      }\n      feature {\n        bytes_list {\n          value: \"In\"\n          value: \"thunder\"\n          value: \",\"\n          value: \"lightning\"\n          value: \",\"\n          value: \"or\"\n          value: \"in\"\n          value: \"rain\"\n          value: \"?\"\n        }\n      }\n    }\n  }\n}"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "sequence_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_sequence_example = sequence_example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_feature_descriptions = {\n",
    "    \"author_id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"title\": tf.io.VarLenFeature(tf.string),\n",
    "    \"pub_date\": tf.io.FixedLenFeature([3], tf.int64, default_value=[0, 0, 0]),\n",
    "}\n",
    "sequence_feature_descriptions = {\n",
    "    \"content\": tf.io.VarLenFeature(tf.string),\n",
    "    \"comments\": tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
    "    serialized_sequence_example, context_feature_descriptions,\n",
    "    sequence_feature_descriptions)"
   ]
  },
  {
   "source": [
    "## The Features API = Preprocessing the Input Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n0    -122.23     37.88                41.0        880.0           129.0   \n1    -122.22     37.86                21.0       7099.0          1106.0   \n2    -122.24     37.85                52.0       1467.0           190.0   \n3    -122.25     37.85                52.0       1274.0           235.0   \n4    -122.25     37.85                52.0       1627.0           280.0   \n\n   population  households  median_income  median_house_value ocean_proximity  \n0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n4       565.0       259.0         3.8462            342200.0        NEAR BAY  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41.0</td>\n      <td>880.0</td>\n      <td>129.0</td>\n      <td>322.0</td>\n      <td>126.0</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21.0</td>\n      <td>7099.0</td>\n      <td>1106.0</td>\n      <td>2401.0</td>\n      <td>1138.0</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1467.0</td>\n      <td>190.0</td>\n      <td>496.0</td>\n      <td>177.0</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1274.0</td>\n      <td>235.0</td>\n      <td>558.0</td>\n      <td>219.0</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1627.0</td>\n      <td>280.0</td>\n      <td>565.0</td>\n      <td>259.0</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def load_housing_data(housing_path = HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_median_age = tf.feature_column.numeric_column(\"housing_median_age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "NumericColumn(key='housing_median_age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7fe2b05e5d40>)"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "age_mean, age_std = X_mean[1], X_std[1]\n",
    "housing_median_age = tf.feature_column.numeric_column(\n",
    "    \"housing_median_age\", normalizer_fn = lambda x: (x - age_mean) / age_std)\n",
    "housing_median_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "BucketizedColumn(source_column=NumericColumn(key='median_income', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(1.5, 3.0, 4.5, 6.0))"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "median_income = tf.feature_column.numeric_column(\"median_income\")\n",
    "bucketized_income = tf.feature_column.bucketized_column(\n",
    "    median_income, boundaries = [1.5, 3., 4.5, 6.]\n",
    ")\n",
    "bucketized_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "VocabularyListCategoricalColumn(key='ocean_proximity', vocabulary_list=('<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "ocean_prox_vocab = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
    "ocean_proximity = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"ocean_proximity\", ocean_prox_vocab)\n",
    "ocean_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketized_age = tf.feature_column.bucketized_column(\n",
    "    housing_median_age, boundaries = [-1., -0.5, 0.5, 1.])\n",
    "age_and_ocean_proximity = tf.feature_column.crossed_column(\n",
    "    [bucketized_age, ocean_proximity], hash_bucket_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = tf.feature_column.numeric_column(\"latitude\")\n",
    "longitude = tf.feature_column.numeric_column(\"longitude\")\n",
    "\n",
    "bucketized_latitude = tf.feature_column.bucketized_column(\n",
    "    latitude, boundaries=list(np.linspace(32., 42., 20 - 1 ))\n",
    ")\n",
    "bucketized_longitude = tf.feature_column.bucketized_column(\n",
    "    longitude, boundaries=list(np.linspace(-125., -114., 20 - 1))\n",
    ")\n",
    "location = tf.feature_column.crossed_column(\n",
    "    [bucketized_latitude, bucketized_longitude], hash_bucket_size=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_proximity_one_hot = tf.feature_column.indicator_column(ocean_proximity)\n",
    "ocean_proximity_embed = tf.feature_column.embedding_column(ocean_proximity,\n",
    "                                                            dimension=2)"
   ]
  },
  {
   "source": [
    "## Using Feature Columns for Parsing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'housing_median_age': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None),\n 'median_house_value': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)}"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "median_house_value = tf.feature_column.numeric_column(\"median_house_value\")\n",
    "columns = [housing_median_age, median_house_value]\n",
    "feature_descriptions = tf.feature_column.make_parse_example_spec(columns)\n",
    "feature_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data_with_features.tfrecords\") as f:\n",
    "    for x, y in zip(X_train[:,1:2], y_train):\n",
    "        example = Example(features = Features(feature={\n",
    "            \"housing_median_age\" : Feature(float_list=FloatList(value=[x])),\n",
    "            \"median_house_value\" : Feature(float_list=FloatList(value=[y]))\n",
    "        }))\n",
    "        f.write(example.SerializeToString())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_examples(serialized_examples):\n",
    "    examples = tf.io.parse_example(serialized_examples, feature_descriptions)\n",
    "    targets = examples.pop(\"median_house_value\")\n",
    "    return examples, targets\n",
    "\n",
    "batch_size = 32\n",
    "dataset = tf.data.TFRecordDataset([\"my_data_with_features.tfrecords\"])\n",
    "dataset = dataset.repeat().shuffle(1000).batch(batch_size).map(parse_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n362/362 [==============================] - 0s 1ms/step - loss: 3.6279 - accuracy: 0.0021\nEpoch 2/5\n362/362 [==============================] - 0s 1ms/step - loss: 1.8660 - accuracy: 0.0030\nEpoch 3/5\n362/362 [==============================] - 0s 1ms/step - loss: 1.4559 - accuracy: 0.0029\nEpoch 4/5\n362/362 [==============================] - 0s 1ms/step - loss: 1.3649 - accuracy: 0.0029\nEpoch 5/5\n362/362 [==============================] - 0s 1ms/step - loss: 1.3257 - accuracy: 0.0028\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fe3e8184790>"
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "columns_without_target = columns[:-1]\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns=columns_without_target),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(dataset, steps_per_epoch=len(X_train) // batch_size, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(3, 7), dtype=float32, numpy=\narray([[ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n         0.7722148 , -0.48437068],\n       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n        -0.59789485,  0.60030633],\n       [ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        -0.59789485,  0.60030633]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "some_columns = [ocean_proximity_embed, bucketized_income]\n",
    "dense_features = keras.layers.DenseFeatures(some_columns)\n",
    "dense_features({\n",
    "    \"ocean_proximity\": [[\"NEAR OCEAN\"], [\"INLAND\"], [\"INLAND\"]],\n",
    "    \"median_income\": [[3.], [7.2], [1.]]\n",
    "})"
   ]
  },
  {
   "source": [
    "## TF Transform"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "data will be handled just befor training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_transform'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-f7641818758e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_transform\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmedian_age\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"housing_median_age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mocean_proximity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ocean_proximity\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_transform'"
     ]
    }
   ],
   "source": [
    "import tensorflow_transform as tft # not installed\n",
    "\n",
    "def preprocess(inputs):\n",
    "    median_age = inputs[\"housing_median_age\"]\n",
    "    ocean_proximity = inputs[\"ocean_proximity\"]\n",
    "    standardized_age = tft.scale_to_z_score(median_age - tft.mean(median_age))\n",
    "    ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
    "    return {\n",
    "        \"standardized_median_age\": standardized_age,\n",
    "        \"ocean_proximity_id\" : ocean_proximity_id\n",
    "    }"
   ]
  },
  {
   "source": [
    "## TensorFlow Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/hs_min/tensorflow_datasets/mnist/3.0.1...\u001b[0m\nWARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\nlocal data directory. If you'd instead prefer to read directly from our public\nGCS bucket (recommended if you're running on GCP), you can instead pass\n`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8e0c674669049e6ad198ce8675838be"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n\u001b[1mDataset mnist downloaded and prepared to /home/hs_min/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
    }
   ],
   "source": [
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['abstract_reasoning', 'aeslc', 'aflw2k3d', 'ai2_arc', 'amazon_us_reviews', 'anli', 'arc', 'bair_robot_pushing_small', 'beans', 'big_patent', 'bigearthnet', 'billsum', 'binarized_mnist', 'binary_alpha_digits', 'blimp', 'c4', 'caltech101', 'caltech_birds2010', 'caltech_birds2011', 'cars196', 'cassava', 'cats_vs_dogs', 'celeb_a', 'celeb_a_hq', 'cfq', 'chexpert', 'cifar10', 'cifar100', 'cifar10_1', 'cifar10_corrupted', 'citrus_leaves', 'cityscapes', 'civil_comments', 'clevr', 'clinc_oos', 'cmaterdb', 'cnn_dailymail', 'coco', 'coil100', 'colorectal_histology', 'colorectal_histology_large', 'common_voice', 'cos_e', 'cosmos_qa', 'covid19sum', 'crema_d', 'curated_breast_imaging_ddsm', 'cycle_gan', 'deep_weeds', 'definite_pronoun_resolution', 'dementiabank', 'diabetic_retinopathy_detection', 'div2k', 'dmlab', 'downsampled_imagenet', 'dsprites', 'dtd', 'duke_ultrasound', 'emnist', 'eraser_multi_rc', 'esnli', 'eurosat', 'fashion_mnist', 'flic', 'flores', 'food101', 'forest_fires', 'fuss', 'gap', 'geirhos_conflict_stimuli', 'german_credit_numeric', 'gigaword', 'glue', 'groove', 'higgs', 'horses_or_humans', 'i_naturalist2017', 'imagenet2012', 'imagenet2012_corrupted', 'imagenet2012_real', 'imagenet2012_subset', 'imagenet_a', 'imagenet_resized', 'imagenet_v2', 'imagenette', 'imagewang', 'imdb_reviews', 'irc_disentanglement', 'iris', 'kitti', 'kmnist', 'lfw', 'librispeech', 'librispeech_lm', 'libritts', 'ljspeech', 'lm1b', 'lost_and_found', 'lsun', 'malaria', 'math_dataset', 'mctaco', 'mnist', 'mnist_corrupted', 'movie_lens', 'movie_rationales', 'moving_mnist', 'multi_news', 'multi_nli', 'multi_nli_mismatch', 'natural_questions', 'newsroom', 'nsynth', 'nyu_depth_v2', 'omniglot', 'open_images_challenge2019_detection', 'open_images_v4', 'openbookqa', 'opinion_abstracts', 'opinosis', 'opus', 'oxford_flowers102', 'oxford_iiit_pet', 'para_crawl', 'patch_camelyon', 'pet_finder', 'pg19', 'places365_small', 'plant_leaves', 'plant_village', 'plantae_k', 'qa4mre', 'quickdraw_bitmap', 'reddit', 'reddit_disentanglement', 'reddit_tifu', 'resisc45', 'robonet', 'rock_paper_scissors', 'rock_you', 'samsum', 'savee', 'scan', 'scene_parse150', 'scicite', 'scientific_papers', 'shapes3d', 'smallnorb', 'snli', 'so2sat', 'speech_commands', 'squad', 'stanford_dogs', 'stanford_online_products', 'starcraft_video', 'stl10', 'sun397', 'super_glue', 'svhn_cropped', 'ted_hrlr_translate', 'ted_multi_translate', 'tedlium', 'tf_flowers', 'the300w_lp', 'tiny_shakespeare', 'titanic', 'trivia_qa', 'uc_merced', 'ucf101', 'vctk', 'vgg_face2', 'visual_domain_decathlon', 'voc', 'voxceleb', 'voxforge', 'waymo_open_dataset', 'web_questions', 'wider_face', 'wiki40b', 'wikihow', 'wikipedia', 'wikipedia_toxicity_subtypes', 'winogrande', 'wmt14_translate', 'wmt15_translate', 'wmt16_translate', 'wmt17_translate', 'wmt18_translate', 'wmt19_translate', 'wmt_t2t_translate', 'wmt_translate', 'wordnet', 'xnli', 'xsum', 'yelp_polarity_reviews']\n"
    }
   ],
   "source": [
    "print(tfds.list_builders())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x216 with 5 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"105.856013pt\" version=\"1.1\" viewBox=\"0 0 373.951059 105.856013\" width=\"373.951059pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 105.856013 \nL 373.951059 105.856013 \nL 373.951059 -0 \nL 0 -0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 29.47 80.042263 \nL 87.194138 80.042263 \nL 87.194138 22.318125 \nL 29.47 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p561a7767b7)\">\n    <image height=\"58\" id=\"image059b467822\" transform=\"scale(1 -1)translate(0 -58)\" width=\"58\" x=\"29.47\" xlink:href=\"data:image/png;base64,\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\" y=\"-22.042263\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m2d5aa7559b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.500788\" xlink:href=\"#m2d5aa7559b\" y=\"80.042263\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(26.683288 96.160388)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.040197\" xlink:href=\"#m2d5aa7559b\" y=\"80.042263\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(74.405197 96.160388)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_3\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"md62974ff9d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#md62974ff9d\" y=\"23.348913\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0 -->\n      <g transform=\"translate(14.835 27.907976)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#md62974ff9d\" y=\"64.58044\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 69.139503)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 29.47 80.042263 \nL 29.47 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 87.194138 80.042263 \nL 87.194138 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 29.47 80.042263 \nL 87.194138 80.042263 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 29.47 22.318125 \nL 87.194138 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_5\">\n    <!-- 4 -->\n    <defs>\n     <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n    </defs>\n    <g transform=\"translate(54.514569 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-52\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 98.738966 80.042263 \nL 156.463103 80.042263 \nL 156.463103 22.318125 \nL 98.738966 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p31d61f2052)\">\n    <image height=\"58\" id=\"image9a8d3cc7ba\" transform=\"scale(1 -1)translate(0 -58)\" width=\"58\" x=\"98.738966\" xlink:href=\"data:image/png;base64,\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\" y=\"-22.042263\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"99.769754\" xlink:href=\"#m2d5aa7559b\" y=\"80.042263\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(95.952254 96.160388)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"151.309163\" xlink:href=\"#m2d5aa7559b\" y=\"80.042263\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 25 -->\n      <g transform=\"translate(143.674163 96.160388)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_3\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"98.738966\" xlink:href=\"#md62974ff9d\" y=\"23.348913\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(84.103966 27.907976)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"98.738966\" xlink:href=\"#md62974ff9d\" y=\"64.58044\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 20 -->\n      <g transform=\"translate(76.468966 69.139503)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 98.738966 80.042263 \nL 98.738966 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 156.463103 80.042263 \nL 156.463103 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 98.738966 80.042263 \nL 156.463103 80.042263 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 98.738966 22.318125 \nL 156.463103 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_10\">\n    <!-- 1 -->\n    <defs>\n     <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n    </defs>\n    <g transform=\"translate(123.783534 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-49\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_12\">\n    <path d=\"M 168.007931 80.042263 \nL 225.732069 80.042263 \nL 225.732069 22.318125 \nL 168.007931 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p7127c7b83b)\">\n    <image height=\"58\" id=\"imageacb783a85c\" transform=\"scale(1 -1)translate(0 -58)\" width=\"58\" x=\"168.007931\" xlink:href=\"data:image/png;base64,\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\" y=\"-22.042263\"/>\n   </g>\n   <g id=\"matplotlib.axis_5\">\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"169.038719\" xlink:href=\"#m2d5aa7559b\" y=\"80.042263\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0 -->\n      <g transform=\"translate(165.221219 96.160388)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"220.578128\" xlink:href=\"#m2d5aa7559b\" y=\"80.042263\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(212.943128 96.160388)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_6\">\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"168.007931\" xlink:href=\"#md62974ff9d\" y=\"23.348913\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0 -->\n      <g transform=\"translate(153.372931 27.907976)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"168.007931\" xlink:href=\"#md62974ff9d\" y=\"64.58044\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 20 -->\n      <g transform=\"translate(145.737931 69.139503)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 168.007931 80.042263 \nL 168.007931 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 225.732069 80.042263 \nL 225.732069 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 168.007931 80.042263 \nL 225.732069 80.042263 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 168.007931 22.318125 \nL 225.732069 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_15\">\n    <!-- 0 -->\n    <g transform=\"translate(193.0525 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-48\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_4\">\n   <g id=\"patch_17\">\n    <path d=\"M 237.276897 80.042263 \nL 295.001034 80.042263 \nL 295.001034 22.318125 \nL 237.276897 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pc9a09c8781)\">\n    <image height=\"58\" id=\"image5b7f52602e\" transform=\"scale(1 -1)translate(0 -58)\" width=\"58\" x=\"237.276897\" xlink:href=\"data:image/png;base64,\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\" y=\"-22.042263\"/>\n   </g>\n   <g id=\"matplotlib.axis_7\">\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"238.307685\" xlink:href=\"#m2d5aa7559b\" y=\"80.042263\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0 -->\n      <g transform=\"translate(234.490185 96.160388)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"289.847094\" xlink:href=\"#m2d5aa7559b\" y=\"80.042263\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 25 -->\n      <g transform=\"translate(282.212094 96.160388)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_8\">\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"237.276897\" xlink:href=\"#md62974ff9d\" y=\"23.348913\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 0 -->\n      <g transform=\"translate(222.641897 27.907976)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"237.276897\" xlink:href=\"#md62974ff9d\" y=\"64.58044\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 20 -->\n      <g transform=\"translate(215.006897 69.139503)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 237.276897 80.042263 \nL 237.276897 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 295.001034 80.042263 \nL 295.001034 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 237.276897 80.042263 \nL 295.001034 80.042263 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 237.276897 22.318125 \nL 295.001034 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_20\">\n    <!-- 7 -->\n    <defs>\n     <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n    </defs>\n    <g transform=\"translate(262.321466 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-55\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_5\">\n   <g id=\"patch_22\">\n    <path d=\"M 306.545862 80.042263 \nL 364.27 80.042263 \nL 364.27 22.318125 \nL 306.545862 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pdce6ccf269)\">\n    <image height=\"58\" id=\"image0ccded3b3a\" transform=\"scale(1 -1)translate(0 -58)\" width=\"58\" x=\"306.545862\" xlink:href=\"data:image/png;base64,\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\" y=\"-22.042263\"/>\n   </g>\n   <g id=\"matplotlib.axis_9\">\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"307.57665\" xlink:href=\"#m2d5aa7559b\" y=\"80.042263\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 0 -->\n      <g transform=\"translate(303.75915 96.160388)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"359.116059\" xlink:href=\"#m2d5aa7559b\" y=\"80.042263\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 25 -->\n      <g transform=\"translate(351.481059 96.160388)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_10\">\n    <g id=\"ytick_9\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"306.545862\" xlink:href=\"#md62974ff9d\" y=\"23.348913\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 0 -->\n      <g transform=\"translate(291.910862 27.907976)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"306.545862\" xlink:href=\"#md62974ff9d\" y=\"64.58044\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 20 -->\n      <g transform=\"translate(284.275862 69.139503)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 306.545862 80.042263 \nL 306.545862 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 364.27 80.042263 \nL 364.27 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 306.545862 80.042263 \nL 364.27 80.042263 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 306.545862 22.318125 \nL 364.27 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_25\">\n    <!-- 8 -->\n    <defs>\n     <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n    </defs>\n    <g transform=\"translate(331.590431 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-56\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p561a7767b7\">\n   <rect height=\"57.724138\" width=\"57.724138\" x=\"29.47\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p31d61f2052\">\n   <rect height=\"57.724138\" width=\"57.724138\" x=\"98.738966\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p7127c7b83b\">\n   <rect height=\"57.724138\" width=\"57.724138\" x=\"168.007931\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"pc9a09c8781\">\n   <rect height=\"57.724138\" width=\"57.724138\" x=\"237.276897\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"pdce6ccf269\">\n   <rect height=\"57.724138\" width=\"57.724138\" x=\"306.545862\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "mnist_train = mnist_train.repeat(5).batch(32).prefetch(1)\n",
    "for item in mnist_train:\n",
    "    images = item['image']\n",
    "    labels = item['label']\n",
    "    for index in range(5):\n",
    "        plt.subplot(1,5,index+1)\n",
    "        image = images[index, ..., 0]\n",
    "        label = labels[index].numpy()\n",
    "        plt.imshow(image,cmap='binary')\n",
    "        plt.title(label)\n",
    "        plt.axis='off'\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(32, 28, 28, 1)\n[4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n"
    }
   ],
   "source": [
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]\n",
    "mnist_train = mnist_train.repeat(5).batch(32)\n",
    "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "mnist_train = mnist_train.prefetch(1)\n",
    "for images, labels in mnist_train.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels.numpy())"
   ]
  },
  {
   "source": [
    "## TensorFlow Hub"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nkeras_layer (KerasLayer)     (None, 50)                48190600  \n_________________________________________________________________\ndense_1 (Dense)              (None, 16)                816       \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 48,191,433\nTrainable params: 833\nNon-trainable params: 48,190,600\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
    "                           output_shape=[50], input_shape=[], dtype=tf.string)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tf.constant([\"It was a great movie\", \"The actors were amazing\"])\n",
    "embeddings = hub_layer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\narray([[ 7.45939985e-02,  2.76720114e-02,  9.38646123e-02,\n         1.25124469e-01,  5.40293928e-04, -1.09435350e-01,\n         1.34755149e-01, -9.57818255e-02, -1.85177118e-01,\n        -1.69703495e-02,  1.75612606e-02, -9.06603858e-02,\n         1.12110220e-01,  1.04646273e-01,  3.87700424e-02,\n        -7.71859884e-02, -3.12189370e-01,  6.99466765e-02,\n        -4.88970093e-02, -2.99049795e-01,  1.31183028e-01,\n        -2.12630898e-01,  6.96169436e-02,  1.63592950e-01,\n         1.05169769e-02,  7.79720694e-02, -2.55230188e-01,\n        -1.80790052e-01,  2.93739915e-01,  1.62875261e-02,\n        -2.80566931e-01,  1.60284728e-01,  9.87277832e-03,\n         8.44555616e-04,  8.39456245e-02,  3.24002892e-01,\n         1.53253034e-01, -3.01048346e-02,  8.94618109e-02,\n        -2.39153411e-02, -1.50188789e-01, -1.81733668e-02,\n        -1.20483577e-01,  1.32937476e-01, -3.35325629e-01,\n        -1.46504581e-01, -1.25251599e-02, -1.64428815e-01,\n        -7.00765476e-02,  3.60923223e-02],\n       [-1.56998575e-01,  4.24599349e-02, -5.57703003e-02,\n        -8.08446854e-03,  1.23733155e-01,  3.89427543e-02,\n        -4.37901802e-02, -1.86987907e-01, -2.29341656e-01,\n        -1.27766818e-01,  3.83025259e-02, -1.07057482e-01,\n        -6.11584112e-02,  2.49654502e-01, -1.39712945e-01,\n        -3.91289443e-02, -1.35873526e-01, -3.58613044e-01,\n         2.53462754e-02, -1.58370987e-01, -1.38350084e-01,\n        -3.90771806e-01, -6.63642734e-02, -3.24838236e-02,\n        -2.20453963e-02, -1.68282315e-01, -7.40613639e-02,\n        -2.49074101e-02,  2.46460736e-01,  9.87201929e-05,\n        -1.85390845e-01, -4.92824614e-02,  1.09015472e-01,\n        -9.54203904e-02, -1.60352528e-01, -2.59811729e-02,\n         1.13778859e-01, -2.09578887e-01,  2.18261331e-01,\n        -3.11211571e-02, -6.12562597e-02, -8.66057724e-02,\n        -1.10762455e-01, -5.73977083e-03, -1.08923554e-01,\n        -1.72919363e-01,  1.00515485e-01, -5.64153939e-02,\n        -4.97694984e-02, -1.07776590e-01]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "embeddings"
   ]
  }
 ]
}